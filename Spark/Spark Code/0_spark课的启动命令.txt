启动hadoop集群：start-all.sh
start-stop.sh

启动vscode：code

登录mysql：mysql -u root -p

启动hive：
进入到hive目录，输入bin/hive
进入hive（里面就是hql命令）：
第一启动hive原：hive --service metastore
第二：直接输入hive

启动spark：
1.进入spark/sbin目录
2.  ./start-all.sh启动spark组件
3.另一个终端进入spark/bin目录输入spark-shell

spark提交代码：spark-submit 028_socket.py [localhost 9999]  #socket必须两个参数
发送端口：nc -lk 9999

启动kafka：需要四个端口
1.zookeeper-server-start.sh /opt/apps/kafka/config/zookeeper.properties
2.kafka-server-start.sh /opt/apps/kafka/config/server.properties
3.查看话题：kafka-topics.sh --list --zookeeper localhost:2181
4.生产者（发话题）：kafka-console-producer.sh --broker-list localhost:9092 --topic test
5.消费者（看话题）：kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

hdfs：start-dfs.sh
